{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "goal_oriented (manual).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_llRN4JYgQV",
        "colab_type": "text"
      },
      "source": [
        "Imports the libraries and file directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8nDzUFRY_gb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-NU72waZFU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fid = drive.ListFile({'q':\"title='goal-oriented.zip'\"}).GetList()[0]['id']\n",
        "f = drive.CreateFile({'id': fid})\n",
        "f.GetContentFile('goal-oriented.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5wjBwEyZFXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with ZipFile('goal-oriented.zip','r') as zipObj:\n",
        "  zipObj.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VnWtnalZFZ1",
        "colab_type": "code",
        "outputId": "17e3be1c-75d0-4526-9777-22f113c36d46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!ls /content/goal-oriented"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "assets\t\t    dqn_agent.py\t       state_tracker.py   utils.py\n",
            "constants.json\t    error_model_controller.py  test.py\t\t  weights\n",
            "data\t\t    LICENSE\t\t       train.py\n",
            "db_query.py\t    pickle_converter.py        user.py\n",
            "dialogue_config.py  README.md\t\t       user_simulator.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-h6pFwxZFcG",
        "colab_type": "code",
        "outputId": "f23794f3-c3cf-43f9-f3dd-5e2606336399",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/goal-oriented"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/goal-oriented\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwxNQ_Q4YnJz",
        "colab_type": "text"
      },
      "source": [
        "# datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcK7-tvlOwFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_1 = {\"0\": {'from_stop': 'hamilton', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '10:30am', 'arrival_time': '12:30pm'},\n",
        "\"1\": {'from_stop': 'hamilton', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '10:30am', 'arrival_time': '12:30pm'},\n",
        "\"2\": {'from_stop': 'nyc', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '30 minutes', 'departure_time': '8:00am', 'arrival_time': '9:00am'},\n",
        "\"3\": {'from_stop': 'belleville', 'to_stop': 'arlington','vehicle': 'subway', 'direction': 'arlington', 'duration': '1 hour', 'departure_time': '11:30am', 'arrival_time': '12:30pm'},\n",
        "\"4\": {'from_stop': 'sacramento', 'to_stop': 'du Quoin','vehicle': 'subway', 'direction': 'sacramento', 'duration': '20 minutes', 'departure_time': '10:30am', 'arrival_time': '10:50pm'}, \n",
        "\"5\": {'from_stop': 'buford', 'to_stop': 'sappington','vehicle': 'subway', 'direction': 'sappington', 'duration': '3 hours', 'departure_time': '11:30am', 'arrival_time': '2:30pm'},\n",
        "\"6\": {'from_stop': 'detroit', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '8:00pm', 'arrival_time': '9:00 pm'}, \n",
        "\"7\": {'from_stop': 'baltimore', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '4 pm', 'arrival_time': '6:15pm'},\n",
        "\"8\":{'from_stop': 'sparta', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '9:30pm', 'arrival_time': '1:10'}, \n",
        "\"9\": {'from_stop': 'princeton', 'to_stop': 'baltimore','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '6:30pm', 'arrival_time': '10:40pm'}, \n",
        "\"10\": {'from_stop': 'knoxville', 'to_stop': 'Springfield','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '11pm', 'arrival_time': '2:30'}, \n",
        "\"11\": {'from_stop': 'tulare', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '40 minutes', 'departure_time': '6:05', 'arrival_time': '6:45'}, \n",
        "\"12\": {'from_stop': 'whittier', 'to_stop': 'nashville','vehicle': 'subway', 'direction': 'nyc', 'duration': '20 minutes', 'departure_time': '10:30am', 'arrival_time': '12:30pm'}, \n",
        "\"13\": {'from_stop': 'Seattle', 'to_stop': 'albany','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '9:50 pm', 'arrival_time': '10:40pm'},\n",
        "\"14\": {'from_stop': 'hamilton', 'to_stop': 'Seattle','vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '7:05pm', 'arrival_time': '7:50pm'}}\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x53Dm-9xjxQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "filename = 'movie_db'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(dic_1,outfile)\n",
        "outfile.close()\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhdq_KIkR3NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_2 ={'from_stop': ['hamilton', 'manville', 'bridgewater', 'seattle', 'bellevue', 'birmingham', 'san francisco', 'portland', 'royal oak', 'Royal Oak', 'madison heights', 'detroit', 'des moines', 'johnstown', 'boston', 'carbondale', 'los angeles', 'stony brook', '94952', 'tampa', 'hoover', 'dramas', 'Sacramento', 'nashville', 'Seattle', 'st louis', 'whittier village stadium cinemas', 'southeast portland', 'miami', 'chicago', 'nyc', 'sacramento', 'pittsburgh', 'atlanta', 'south barrington', 'over seattle', 'dallas', 'st', 'louis park', 'Portland', 'Monroe', 'cary', 'whittier', 'sparta', 'Shiloh', 'Belleville', \"o'fallon\", 'fairview heights', 'springfield', 'albany', 'houma', 'la', 'evanston', 'Southfield', 'monroe', 'Long Island', 'northern san francisco', '94109', 'louis', 'sappington', 'norfolk', 'Los Angeles CA 90015', 'campcreek area', 'regency', 'arlington', 'philadelphia', 'princeton', 'buford', 'las vegas', 'waynesboro', 'Clear Lake', 'du quoin', 'Du Quoin', 'altoona', 'orlando', 'regency academy 6 theater', 'baltimore', 'knoxville', 'chico', 'wilmington', 'lansing', 'bayou vista', 'manchester stadium 16', 'Houma', 'tulare', 'shiloh', 'belleville', 'Springfield', 'du Quoin'], 'to_stop': ['hamilton', 'manville', 'bridgewater', 'seattle', 'bellevue', 'birmingham', 'san francisco', 'portland', 'royal oak', 'Royal Oak', 'madison heights', 'detroit', 'des moines', 'johnstown', 'boston', 'carbondale', 'los angeles', 'stony brook', '94952', 'tampa', 'hoover', 'dramas', 'Sacramento', 'nashville', 'Seattle', 'st louis', 'whittier village stadium cinemas', 'southeast portland', 'miami', 'chicago', 'nyc', 'sacramento', 'pittsburgh', 'atlanta', 'south barrington', 'over seattle', 'dallas', 'st', 'louis park', 'Portland', 'Monroe', 'cary', 'whittier', 'sparta', 'Shiloh', 'Belleville', \"o'fallon\", 'fairview heights', 'springfield', 'albany', 'houma', 'la', 'evanston', 'Southfield', 'monroe', 'Long Island', 'northern san francisco', '94109', 'louis', 'sappington', 'norfolk', 'Los Angeles CA 90015', 'campcreek area', 'regency', 'arlington', 'philadelphia', 'princeton', 'buford', 'las vegas', 'waynesboro', 'Clear Lake', 'du quoin', 'Du Quoin', 'altoona', 'orlando', 'regency academy 6 theater', 'baltimore', 'knoxville', 'chico', 'wilmington', 'lansing', 'bayou vista', 'manchester stadium 16', 'Houma', 'tulare', 'shiloh', 'belleville', 'Springfield', 'du Quoin'],'direction':['hamilton', 'manville', 'bridgewater', 'seattle', 'bellevue', 'birmingham', 'san francisco', 'portland', 'royal oak', 'Royal Oak', 'madison heights', 'detroit', 'des moines', 'johnstown', 'boston', 'carbondale', 'los angeles', 'stony brook', '94952', 'tampa', 'hoover', 'dramas', 'Sacramento', 'nashville', 'Seattle', 'st louis', 'whittier village stadium', 'southeast portland', 'miami', 'chicago', 'nyc', 'sacramento', 'pittsburgh', 'atlanta', 'south barrington', 'over seattle', 'dallas', 'st', 'louis park', 'Portland', 'Monroe', 'cary', 'whittier', 'sparta', 'Shiloh', 'Belleville', \"o'fallon\", 'fairview heights', 'springfield', 'albany', 'houma', 'la', 'evanston', 'Southfield', 'monroe', 'Long Island', 'northern san francisco', '94109', 'louis', 'sappington', 'norfolk', 'Los Angeles CA 90015', 'campcreek area', 'regency', 'arlington', 'philadelphia', 'princeton', 'buford', 'las vegas', 'waynesboro', 'Clear Lake', 'du quoin', 'Du Quoin', 'altoona', 'orlando', 'regency academy 6 theater', 'baltimore', 'knoxville', 'chico', 'wilmington', 'lansing', 'bayou vista', 'manchester stadium 16', 'Houma', 'tulare', 'shiloh', 'belleville', 'Springfield', 'du Quoin'],'departure_time':['10:30am', '8:00am','11:10am', '1:10pm', '7:00pm','1:50pm','9:00am','3:45pm', '4:30pm', '5:20pm', '6:30pm', '1:00pm','7:15pm', '9:10pm', '10:30pm', '12:30pm', '9:30pm', '9:30', '8:40pm', '7:00pm', '9:50pm', 'none', 'before 4pm', '12:00', '1:10', '2:40', '3:50', 'around 2pm', '1:30', '4:00', 'night', '11:05am', '1:45pm', '7:20 pm', '4:35pm', '10pm', '10 pm', 'latest showing', '9:00 pm','1:30','around 6pm', '7:20', '9:10 pm', '8:45 pm', '8:45', '9:50 pm', 'around 3 pm', '12pm', '9:30 pm', '6pm', '9:01pm', '5:30pm', '8:00pm', '10:40pm', '2:30pm', '5:10pm', '10:00pm', '7:15 pm', '7pm', 'around 7pm', 'earliest showing', '12:45pm', '1:15pm', '12:45', '12:35pm', ' 4:05pm', ' 7:05pm', ' 9:55pm', '7:05 pm', 'after dinner', 'after 7:30pm', '10:50pm', '7:50pm', '10:20pm', '8pm', '8:20', '8:15pm', 'between 9 and 10', '10:20', 'after 7pm', '4:40 pm', 'before dinner', '7:10 pm', 'betwenn 8-10 pm', '4 pm', '4:20', '4:20pm', 'from noon to 4pm', '8:30pm', '11:00pm', '11pm', ' Matinee', '4pm to 7pm', '6:55pm', '11:50am', '5:10', '7:50', '10:25', '2:30', '9:25 pm', '2:35 pm', '2:35', 'afternoon', '10:00am', '3:30pm', '6:15pm', '9:00pm', '3:30', '11:30am', '1:05pm', '2:35pm','10:00pm','4:10pm', '5:40pm', '7:05pm', '8:35pm', '9:55pm', '10:05am', '11:00am', '2:00pm', '4:05pm', '4:50pm', '6:45pm', '7:45pm', '10:45am', '11:15am', '1:00pm', '2:15pm', '4:00pm', '4:45pm', '5:15pm', '7:30pm', 'morning', '7:00 pm', '12:15pm', '3:00pm', '5:45pm', '10:00 pm', '4:50 pm', '7:05', 'around 4pm', '4 PM', '8:00 pm', '8:40', '8:00', '8', '5pm', '5:00 pm', 'around 8 pm', '1:30pm', '4pm', '130pm', 'closest to noon', 'late showing', 'anytime after 7pm', '4:10&&7:00&&9:50pm', '4:40&&7:30&&10:20', '2pm', '2:20 pm', '11:45am', 'around 9pm', '9pm', '8:25pm', '9:05pm', '9:05', '9:45pm', 'around 7 pm', '8:45pm', '5:25pm', '5:25', '317', '10:25pm', '9:55', '6:25', ' 9:00 pm', '7:55pm', '10:45pm', '11:55pm', '10:10am', '1:25pm', '2:20pm', '3:50pm', '7:10pm', '9:35pm', '11:10pm', '12:05am', '7:30', '7:00', 'around 6 pm', '5:20', '6:30', '4:10', '4:40', '10:15pm', '10:15', '12:05pm', '6:25pm', 'after 5 pm', '930pm', '640pm', 'night around 8pm', \"8 o'clock\", '9:20 pm', '9:20', '12:20pm', '3:40pm', '6:50pm', '8:40pm tonight', 'around 8pm', '9:10', '605pm', '6 pm', '2:20PM', '2:20', 'between noon and 4pm', 'early', '10:35', '11:40 am', 'between 2 and 4pm', '6:55', '6:10pm', '7:20pm', '7:25pm', '9:20pm', '2 pm', 'soonest', '12:40pm', '3:40', '6:50', '10:00', '10 o clock', '5:00pm', '7:40pm', '740', '10 cloverfield lane', ' 6:30pm', ' 9:10pm', ' 11:55pm', 'roughly every hour', '9:45 pm', '7', '4:40pm', 'matinee', 'evening', '8:20 pm', 'tonight', '7:30 pm', '8:15 pm', '8:15am', 'after 6 pm', '6:45', ' around 7pm', '4:25 pm', '7:15', '7:10', '10:05', '7:25 pm', 'pm', 'any time', '12:20', 'later in the evening', '12:00pm', 'between 5pm and 6pm', 'between 5 and 6pm', 'around noon', 'soonest upcoming showing', '6:05', '7:25', '1:35 pm', '4:30', 'around 5pm', '2:00 pm', '1:35pm', '9:25pm', '8:10PM', 'evening around 6pm', '6:30 pm', '5:50', '6:40 pm', 'a lot', 'sonnest', '705pm', '635pm', '6:35', '1:15', '7 pm', '6:40pm', 'anytime after 6pm', 'between 8 and 10 pm', '8 pm', '6:00pm', '11:40pm', '1:30 pm', '3:20pm', '8:05', '11:40', 'between 8 and 9pm', '9:25', 'after 7 pm', '5:50pm', '2:25pm', '2:25', 'between say 4pm and 7pm', 'evening around 7', ' 10:30', 'the next', 'the next showing', '2:05 pm', '7:40', '6:00', '8:30', 'between 4pm and 7pm', '730pm', 'early afternoon', ' 7:40pm', ' 10:10pm', '1:50', ' 4:30', ' 7:10', ' 9:50', '2:40pm', 'kinky there', '7:35 pm', '7:35', 'midnight', 'late', 'from 4pm to 7pm', '1:55', '4:25', 'anytime', 'once or twice every hour', '340pm', ' 425pm', '4:25pm', '425pm', '9', '10', 'some time close to that', '11:20am', 'between 8-10 pm', '8:05pm', '10:35pm', 'after 6pm', '11:20', '12:35', 'right now', '1:55pm', '10:05pm', '10:05 pm'],'vehicle':['bus','subway'],'line':['bus','subway'],'arrival_time':['10:30am','9:00am','1:00pm','8:00am','11:10am', '1:10pm', '1:50pm', '3:45pm', '4:30pm', '5:20pm', '6:30pm', '7:15pm', '9:10pm', '10:30pm', '12:30pm', '9:30pm', '9:30', '8:40pm', '7:00pm', '9:50pm', 'none', 'before 4pm', '12:00', '1:10', '2:40', '3:50', 'around 2pm', '1:30', '4:00', 'night', '11:05am', '1:45pm', '7:20 pm', '4:35pm', '10pm', '10 pm', 'latest showing', '9:00 pm', 'around 6pm', '7:20', '9:10 pm', '8:45 pm', '8:45', '9:50 pm', 'around 3 pm', '12pm', '9:30 pm', '6pm', '9:01pm', '5:30pm', '8:00pm', '10:40pm', '2:30pm', '5:10pm', '10:00pm', '7:15 pm', '7pm', 'around 7pm', 'earliest showing', '12:45pm', '1:15pm', '12:45', '12:35pm', ' 4:05pm', ' 7:05pm', ' 9:55pm', '7:05 pm', 'after dinner', 'after 7:30pm', '10:50pm', '7:50pm', '10:20pm', '8pm', '8:20', '8:15pm', 'between 9 and 10', '10:20', 'after 7pm', '4:40 pm', 'before dinner', '7:10 pm', 'betwenn 8-10 pm', '4 pm', '4:20', '4:20pm', 'from noon to 4pm', '8:30pm', '11:00pm', '11pm', ' Matinee', '4pm to 7pm', '6:55pm', '11:50am', '5:10', '7:50', '10:25', '2:30', '9:25 pm', '2:35 pm', '2:35', 'afternoon', '10:00am', '3:30pm', '6:15pm', '9:00pm', '3:30', '11:30am', '1:05pm', '2:35pm', '4:10pm', '5:40pm', '7:05pm', '8:35pm', '9:55pm', '10:05am', '11:00am', '2:00pm', '4:05pm', '4:50pm', '6:45pm', '7:45pm', '10:45am', '11:15am', '1:00pm', '2:15pm', '4:00pm', '4:45pm', '5:15pm', '7:30pm', 'morning', '7:00 pm', '12:15pm', '3:00pm', '5:45pm', '10:00 pm', '4:50 pm', '7:05', 'around 4pm', '4 PM', '8:00 pm', '8:40', '8:00', '8', '5pm', '5:00 pm', 'around 8 pm', '1:30pm', '4pm', '130pm', 'closest to noon', 'late showing', 'anytime after 7pm', '4:10&&7:00&&9:50pm', '4:40&&7:30&&10:20', '2pm', '2:20 pm', '11:45am', 'around 9pm', '9pm', '8:25pm', '9:05pm', '9:05', '9:45pm', 'around 7 pm', '8:45pm', '5:25pm', '5:25', '317', '10:25pm', '9:55', '6:25', ' 9:00 pm', '7:55pm', '10:45pm', '11:55pm', '10:10am', '1:25pm', '2:20pm', '3:50pm', '7:10pm', '9:35pm', '11:10pm', '12:05am', '7:30', '7:00', 'around 6 pm', '5:20', '6:30', '4:10', '4:40', '10:15pm', '10:15', '12:05pm', '6:25pm', 'after 5 pm', '930pm', '640pm', 'night around 8pm', '8 oclock',\n",
        " '9:20 pm', '9:20', '12:20pm', '3:40pm', '6:50pm', '8:40pm tonight', 'around 8pm', '9:10', '605pm', '6 pm', '2:20PM', '2:20', 'between noon and 4pm', 'early', '10:35', '11:40 am', 'between 2 and 4pm', '6:55', '6:10pm', '7:20pm', '7:25pm', '9:20pm', '2 pm', 'soonest', '12:40pm', '3:40', '6:50', '10:00', '10 o clock', '5:00pm', '7:40pm', '740', '10 cloverfield lane', ' 6:30pm', ' 9:10pm', ' 11:55pm', 'roughly every hour', '9:45 pm', '7', '4:40pm', 'matinee', 'evening', '8:20 pm', 'tonight', '7:30 pm', '8:15 pm', '8:15am', 'after 6 pm', '6:45', ' around 7pm', '4:25 pm', '7:15', '7:10', '10:05', '7:25 pm', 'pm', 'any time', '12:20', 'later in the evening', '12:00pm', 'between 5pm and 6pm', 'between 5 and 6pm', 'around noon', 'soonest upcoming showing', '6:05', '7:25', '1:35 pm', '4:30', 'around 5pm', '2:00 pm', '1:35pm', '9:25pm', '8:10PM', 'evening around 6pm', '6:30 pm', '5:50', '6:40 pm', 'a lot', 'sonnest', '705pm', '635pm', '6:35', '1:15', '7 pm', '6:40pm', 'anytime after 6pm', 'between 8 and 10 pm', '8 pm', '6:00pm', '11:40pm', '1:30 pm', '3:20pm', '8:05', '11:40', 'between 8 and 9pm', '9:25', 'after 7 pm', '5:50pm', '2:25pm', '2:25', 'between say 4pm and 7pm', 'evening around 7', ' 10:30', 'the next', 'the next showing', '2:05 pm', '7:40', '6:00', '8:30', 'between 4pm and 7pm', '730pm', 'early afternoon', ' 7:40pm', ' 10:10pm', '1:50', ' 4:30', ' 7:10', ' 9:50', '2:40pm', 'kinky there', '7:35 pm', '7:35', 'midnight', 'late', 'from 4pm to 7pm', '1:55', '4:25', 'anytime', 'once or twice every hour', '340pm', ' 425pm', '4:25pm', '425pm', '9', '10', 'some time close to that', '11:20am', 'between 8-10 pm', '8:05pm', '10:35pm', 'after 6pm', '11:20', '12:35', 'right now', '1:55pm', '10:05pm', '10:05 pm'],'duration':['10 minutes','20 minutes','15 minutes','25 minutes','30 minutes','40 minutes','50 minutes','1 hour','2 hours','8 minutes','45 minutes','35 minutes','55 minutes','3 hours','15 minutes','5 minutes','35 minutes','60 minutes','54 minutes','100 minutes','34 minutes','6 minutes','12 minutes','33 minutes','56 minutes','17 minutes','154 minutes','58 minutes'],'alternative': ['next', 'previous']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4JvHMpgSbm7",
        "colab_type": "code",
        "outputId": "8db15a31-23de-499e-de31-df966cd89d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'movie_dict'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(dic_2,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1mYfrCWSf-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dic_3= {\"0\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'hamilton', 'to_stop': 'Seattle', 'direction': 'nyc', 'departure_time': '10:30am', 'vehicle': 'bus', 'arrival_time': '12:30pm'}},\n",
        "\"1\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'birmingham', 'to_stop': 'Seattle', 'direction': 'nyc', 'departure_time': '3:40', 'vehicle': 'bus', 'arrival_time': '4:40', 'duration': '1 hour'}},\n",
        "\"2\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'nyc', 'to_stop': 'Seattle','departure_time': '7:00pm', 'vehicle': 'subway', 'arrival_time': '8:00pm', 'duration': '1 hour'}},\n",
        "\"3\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'Seattle', 'to_stop': 'hamilton','departure_time': '9:00 pm', 'vehicle': 'subway', 'arrival_time': '9:45pm', 'duration': '1 hour'}},\n",
        "\"4\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'nashville', 'to_stop': 'stony brook','departure_time': '2pm', 'vehicle': 'bus', 'arrival_time': '2:20 pm', 'duration': '20 minutes'}},\n",
        "\"5\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'Springfield', 'to_stop': 'sacramento','departure_time': '6:30pm', 'vehicle': 'subway', 'arrival_time': '9:10pm', 'duration': '154 minutes'}},\n",
        "\"6\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'baltimore', 'to_stop': 'Seattle','departure_time': '8:00pm', 'vehicle': 'subway','arrival_time':'9:00 pm','duration': '1 hour'}},\n",
        "\"7\": {'request_slots': {'from_stop': 'knoxville', 'to_stop': 'Springfield', 'departure_time': 'UNK'}, 'diaact': 'request', 'inform_slots': {'arrival_time': '2:30', 'duration': '30 minutes'}},\n",
        "\"8\": {'request_slots': {'from_stop': 'sparta', 'to_stop': 'Seattle', 'departure_time': '9:30pm'}, 'diaact': 'request', 'inform_slots': {'arrival_time': '1:10', 'duration': '30 minutes'}},\n",
        "\"9\": {'request_slots': {'from_stop': 'UNK', 'to_stop': 'UNK', 'departure_time': 'UNK'}, 'diaact': 'request', 'inform_slots': {'arrival_time': '11:00pm', 'duration': '30 minutes'}},\n",
        "\"10\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'tulare', 'to_stop': 'Seattle','departure_time': '6:05', 'vehicle': 'bus', 'arrival_time': '6:45', 'duration': '40 minutes'}},\n",
        "\"11\": {'request_slots': {}, 'diaact': 'request', 'inform_slots': {'from_stop': 'whittier', 'to_stop': 'nashville','departure_time': '10:30am', 'vehicle': 'subway', 'arrival_time': '12:30pm', 'duration': '20 minutes'}},\n",
        "\"12\": {'request_slots': {'from_stop': 'UNK', 'to_stop':'UNK'}, 'diaact': 'request', 'inform_slots': {'departure_time': 'tommorow', 'vehicle': 'subway', 'arrival_time': '7:05pm'}}}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8mmMskEUlTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'movie_user_goals'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(dic_3,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOkKh9WzalJY",
        "colab_type": "text"
      },
      "source": [
        "# overwriting the files "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBZXuQazYsIu",
        "colab_type": "text"
      },
      "source": [
        "overwriting file with new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtXNpq7LZFhd",
        "colab_type": "code",
        "outputId": "5a4a40a8-cd61-4269-c605-fa383cd2b935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile dialogue_config.py\n",
        "# Special slot values (for reference)\n",
        "'PLACEHOLDER'  # For informs\n",
        "'UNK'  # For requests\n",
        "'anything'  # means any value works for the slot with this value\n",
        "'no match available'  # When the intent of the agent is match_found yet no db match fits current constraints\n",
        "\n",
        "#######################################\n",
        "# Usersim Config\n",
        "#######################################\n",
        "# Used in EMC for intent error (and in user)\n",
        "usersim_intents = ['inform', 'request', 'thanks', 'reject', 'done']\n",
        "\n",
        "# The goal of the agent is to inform a match for this key\n",
        "usersim_default_key = 'ticket'\n",
        "\n",
        "# Required to be in the first action in inform slots of the usersim if they exist in the goal inform slots\n",
        "usersim_required_init_inform_keys = ['from_stop','to_stop']\n",
        "\n",
        "#######################################\n",
        "# Agent Config\n",
        "#######################################\n",
        "\n",
        "# Possible inform and request slots for the agent\n",
        "agent_inform_slots = ['from_stop', 'to_stop', 'direction', 'departure_time', 'vehicle', 'arrival_time', 'duration', 'alternative',\n",
        "                      usersim_default_key]\n",
        "agent_request_slots = ['from_stop', 'to_stop', 'direction', 'departure_time', 'vehicle', 'arrival_time', 'duration','alternative']\n",
        "\n",
        "# Possible actions for agent\n",
        "agent_actions = [\n",
        "    {'intent': 'done', 'inform_slots': {}, 'request_slots': {}},  # Triggers closing of conversation\n",
        "    {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}}\n",
        "]\n",
        "for slot in agent_inform_slots:\n",
        "    # Must use intent match found to inform this, but still have to keep in agent inform slots\n",
        "    if slot == usersim_default_key:\n",
        "        continue\n",
        "    agent_actions.append({'intent': 'inform', 'inform_slots': {slot: 'PLACEHOLDER'}, 'request_slots': {}})\n",
        "for slot in agent_request_slots:\n",
        "    agent_actions.append({'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}})\n",
        "\n",
        "# Rule-based policy request list\n",
        "rule_requests = ['from_stop', 'to_stop', 'departure_time', 'direction','vehicle']\n",
        "# i took off vechicle from here \n",
        "\n",
        "# These are possible inform slot keys that cannot be used to query\n",
        "no_query_keys = ['duration','alternative','arrival_time','direction', usersim_default_key]\n",
        "\n",
        "#######################################\n",
        "# Global config\n",
        "#######################################\n",
        "\n",
        "# These are used for both constraint check AND success check in usersim\n",
        "FAIL = -1\n",
        "NO_OUTCOME = 0\n",
        "SUCCESS = 1\n",
        "\n",
        "# All possible intents (for one-hot conversion in ST.get_state())\n",
        "all_intents = ['inform', 'request', 'done', 'match_found', 'thanks', 'reject']\n",
        "\n",
        "# All possible slots (for one-hot conversion in ST.get_state())\n",
        "all_slots = ['from_stop', 'to_stop', 'direction', 'departure_time', 'vehicle', 'arrival_time', 'duration', 'alternative',usersim_default_key]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting dialogue_config.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVc_kFBOYxSO",
        "colab_type": "text"
      },
      "source": [
        "# constants file to pass in hyper paramnetrs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KA5mNktMbKlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open('constants.json') as f:\n",
        "  data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml0V43L8Y2nW",
        "colab_type": "text"
      },
      "source": [
        "#set usersim to False to test manually \n",
        "#set usersim to True to automate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD-4CwUxK6Qw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict2 = {\n",
        "  \"db_file_paths\": {\n",
        "    \"database\": \"/content/goal-oriented/movie_db\",\n",
        "    \"dict\": \"/content/goal-oriented/movie_dict\",\n",
        "    \"user_goals\": \"/content/goal-oriented/movie_user_goals\"\n",
        "  },\n",
        "  \"run\": {\n",
        "    \"usersim\": False,\n",
        "    \"warmup_mem\": 1000,\n",
        "    #1000\n",
        "    \"num_ep_run\": 40000,\n",
        "#40000\n",
        "    \"train_freq\": 100,\n",
        "    #100\n",
        "    \"max_round_num\": 20,\n",
        "    \"success_rate_threshold\": 0.3\n",
        "  },\n",
        "  \"agent\": {\n",
        "    \"save_weights_file_path\": \"weights/model.h5\",\n",
        "    \"load_weights_file_path\": \"weights/model.h5\",\n",
        "    \"vanilla\": True,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"batch_size\": 16,\n",
        "    \"dqn_hidden_size\": 80,\n",
        "    \"epsilon_init\": 0.0,\n",
        "    \"gamma\": 0.9,\n",
        "    \"max_mem_size\": 500000\n",
        "  },\n",
        "  \"emc\": {\n",
        "    \"slot_error_mode\": 0,\n",
        "    \"slot_error_prob\": 0.05,\n",
        "    \"intent_error_prob\": 0.0\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbiioqVcLBs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.update(dict2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6eafgMJLQCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('constants.json', 'w') as json_file:\n",
        "  json.dump(data, json_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXHlrs3kLOBa",
        "colab_type": "code",
        "outputId": "59790600-ee4a-49ba-fda0-ce4190b60798",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "!cat constants.json"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"db_file_paths\": {\"database\": \"/content/goal-oriented/movie_db\", \"dict\": \"/content/goal-oriented/movie_dict\", \"user_goals\": \"/content/goal-oriented/movie_user_goals\"}, \"run\": {\"usersim\": false, \"warmup_mem\": 1000, \"num_ep_run\": 40000, \"train_freq\": 100, \"max_round_num\": 20, \"success_rate_threshold\": 0.3}, \"agent\": {\"save_weights_file_path\": \"weights/model.h5\", \"load_weights_file_path\": \"weights/model.h5\", \"vanilla\": true, \"learning_rate\": 0.001, \"batch_size\": 16, \"dqn_hidden_size\": 80, \"epsilon_init\": 0.0, \"gamma\": 0.9, \"max_mem_size\": 500000}, \"emc\": {\"slot_error_mode\": 0, \"slot_error_prob\": 0.05, \"intent_error_prob\": 0.0}}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuoC3E8beVl6",
        "colab_type": "code",
        "outputId": "caf9eb3d-d960-40eb-afd5-50d4f0368687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "%%writefile train.py\n",
        "from user_simulator import UserSimulator\n",
        "from error_model_controller import ErrorModelController\n",
        "from dqn_agent import DQNAgent\n",
        "from state_tracker import StateTracker\n",
        "import pickle, argparse, json, math\n",
        "from utils import remove_empty_slots\n",
        "from user import User\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Can provide constants file path in args OR run it as is and change 'CONSTANTS_FILE_PATH' below\n",
        "    # 1) In terminal: python train.py --constants_path \"constants.json\"\n",
        "    # 2) Run this file as is\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--constants_path', dest='constants_path', type=str, default='')\n",
        "    args = parser.parse_args()\n",
        "    params = vars(args)\n",
        "\n",
        "    # Load constants json into dict\n",
        "    CONSTANTS_FILE_PATH = 'constants.json'\n",
        "    if len(params['constants_path']) > 0:\n",
        "        constants_file = params['constants_path']\n",
        "    else:\n",
        "        constants_file = CONSTANTS_FILE_PATH\n",
        "\n",
        "    with open(constants_file) as f:\n",
        "        constants = json.load(f)\n",
        "\n",
        "    # Load file path constants\n",
        "    file_path_dict = constants['db_file_paths']\n",
        "    DATABASE_FILE_PATH = file_path_dict['database']\n",
        "    DICT_FILE_PATH = file_path_dict['dict']\n",
        "    USER_GOALS_FILE_PATH = file_path_dict['user_goals']\n",
        "\n",
        "    # Load run constants\n",
        "    run_dict = constants['run']\n",
        "    USE_USERSIM = run_dict['usersim']\n",
        "    WARMUP_MEM = run_dict['warmup_mem']\n",
        "    NUM_EP_TRAIN = run_dict['num_ep_run']\n",
        "    TRAIN_FREQ = run_dict['train_freq']\n",
        "    MAX_ROUND_NUM = run_dict['max_round_num']\n",
        "    SUCCESS_RATE_THRESHOLD = run_dict['success_rate_threshold']\n",
        "\n",
        "    # Load movie DB\n",
        "    # Note: If you get an unpickling error here then run 'pickle_converter.py' and it should fix it\n",
        "    database = pickle.load(open(DATABASE_FILE_PATH, 'rb'), encoding='UTF-8')\n",
        "\n",
        "    # Clean DB\n",
        "    remove_empty_slots(database)\n",
        "\n",
        "    # Load movie dict\n",
        "    db_dict = pickle.load(open(DICT_FILE_PATH, 'rb'), encoding='UTF-8')\n",
        "\n",
        "    # Load goal File\n",
        "    user_goals = pickle.load(open(USER_GOALS_FILE_PATH, 'rb'), encoding='UTF-8')\n",
        "\n",
        "    # Init. Objects\n",
        "    if USE_USERSIM:\n",
        "        user = UserSimulator(user_goals, constants, database)\n",
        "    else:\n",
        "        user = User(constants)    \n",
        "    emc = ErrorModelController(db_dict, constants)\n",
        "    state_tracker = StateTracker(database, constants)\n",
        "    dqn_agent = DQNAgent(state_tracker.get_state_size(), constants)\n",
        "\n",
        "\n",
        "def run_round(state, warmup=False):\n",
        "    # 1) Agent takes action given state tracker's representation of dialogue (state)\n",
        "    agent_action_index, agent_action = dqn_agent.get_action(state, use_rule=warmup)\n",
        "    # 2) Update state tracker with the agent's action\n",
        "    state_tracker.update_state_agent(agent_action)\n",
        "    # 3) User takes action given agent action\n",
        "    user_action, reward, done, success = user.step(agent_action)\n",
        "    #print(\"sucess in step:\", success)\n",
        "    if not done:\n",
        "        # 4) Infuse error into semantic frame level of user action\n",
        "        emc.infuse_error(user_action)\n",
        "    # 5) Update state tracker with user action\n",
        "    state_tracker.update_state_user(user_action)\n",
        "    # 6) Get next state and add experience\n",
        "    next_state = state_tracker.get_state(done)\n",
        "    #print(\"next state:\",next_state )\n",
        "    dqn_agent.add_experience(state, agent_action_index, reward, next_state, done)\n",
        "\n",
        "    return next_state, reward, done, success\n",
        "\n",
        "\n",
        "def warmup_run():\n",
        "    \"\"\"\n",
        "    Runs the warmup stage of training which is used to fill the agents memory.\n",
        "    The agent uses it's rule-based policy to make actions. The agent's memory is filled as this runs.\n",
        "    Loop terminates when the size of the memory is equal to WARMUP_MEM or when the memory buffer is full.\n",
        "    \"\"\"\n",
        "\n",
        "    print('Warmup Started...')\n",
        "    total_step = 0\n",
        "    while total_step != WARMUP_MEM and not dqn_agent.is_memory_full():\n",
        "        # Reset episode\n",
        "        episode_reset()\n",
        "        done = False\n",
        "        # Get initial state from state tracker\n",
        "        state = state_tracker.get_state()\n",
        "        while not done:\n",
        "            #print(\"state\", state)\n",
        "            next_state, _, done, _ = run_round(state, warmup=True)\n",
        "            total_step += 1\n",
        "            state = next_state\n",
        "           \n",
        "\n",
        "    print('...Warmup Ended')\n",
        "\n",
        "\n",
        "def train_run():\n",
        "    \"\"\"\n",
        "    Runs the loop that trains the agent.\n",
        "    Trains the agent on the goal-oriented chatbot task. Training of the agent's neural network occurs every episode that\n",
        "    TRAIN_FREQ is a multiple of. Terminates when the episode reaches NUM_EP_TRAIN.\n",
        "    \"\"\"\n",
        "\n",
        "    print('Training Started...')\n",
        "    episode = 0\n",
        "    period_reward_total = 0\n",
        "    period_success_total = 0\n",
        "    success_rate_best = 0.0\n",
        "    while episode < NUM_EP_TRAIN:\n",
        "        episode_reset()\n",
        "        episode += 1\n",
        "        done = False\n",
        "        state = state_tracker.get_state()\n",
        "        #print(\"state:\",state )\n",
        "        while not done:\n",
        "            next_state, reward, done, success = run_round(state)\n",
        "            print(\"success\", success)\n",
        "            period_reward_total += reward\n",
        "            print(\"period_reqards_total:\", period_reward_total )\n",
        "            state = next_state\n",
        "\n",
        "        period_success_total += success\n",
        "        print(\"period_success_total\", period_success_total)\n",
        "        \n",
        "        # Train\n",
        "        #print(\"TRAIN_FREQ\", TRAIN_FREQ, \"episode\", episode)\n",
        "        if episode % TRAIN_FREQ == 0:\n",
        "            # Check success rate\n",
        "            #print(\"Train+FREQ\", TRAIN_FREQ)\n",
        "            success_rate = period_success_total / TRAIN_FREQ\n",
        "            #print(\"success_rate after\", success_rate)\n",
        "            avg_reward = period_reward_total / TRAIN_FREQ\n",
        "            # Flush\n",
        "            if success_rate > success_rate_best and success_rate >=0.1:\n",
        "                dqn_agent.empty_memory()\n",
        "            # Update current best success rate\n",
        "           # print(\"step1 success\")\n",
        "            # print(\"success_rate:\" , success_rate)\n",
        "            # print(\"success_rate_best:\", success_rate_best)\n",
        "            if success_rate > success_rate_best:\n",
        "                print('Episode: {} NEW BEST SUCCESS RATE: {} Avg Reward: {}' .format(episode, success_rate, avg_reward))\n",
        "                success_rate_best = success_rate\n",
        "                dqn_agent.save_weights()\n",
        "            period_success_total = 0\n",
        "            period_reward_total = 0\n",
        "            # Copy\n",
        "            dqn_agent.copy()\n",
        "            # Train\n",
        "            dqn_agent.train()\n",
        "    print('...Training Ended')\n",
        "\n",
        "\n",
        "def episode_reset():\n",
        "    \"\"\"\n",
        "    Resets the episode/conversation in the warmup and training loops.\n",
        "    Called in warmup and train to reset the state tracker, user and agent. Also get's the initial user action.\n",
        "    \"\"\"\n",
        "\n",
        "    # First reset the state tracker\n",
        "    state_tracker.reset()\n",
        "    # Then pick an init user action\n",
        "    user_action = user.reset()\n",
        "    #print(\"user_action\", user_action)\n",
        "    # Infuse with error\n",
        "    emc.infuse_error(user_action)\n",
        "    # And update stauserte tracker\n",
        "    state_tracker.update_state_user(user_action)\n",
        "    # Finally, reset agent\n",
        "    dqn_agent.reset()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "warmup_run()\n",
        "train_run()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCwVjnIptGHh",
        "colab_type": "code",
        "outputId": "81a623f4-eafc-4fea-e877-5632932203ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile user_simulator.py\n",
        "from dialogue_config import usersim_default_key, FAIL, NO_OUTCOME, SUCCESS, usersim_required_init_inform_keys, \\\n",
        "    no_query_keys\n",
        "from utils import reward_function\n",
        "import random, copy\n",
        "\n",
        "\n",
        "class UserSimulator:\n",
        "    \"\"\"Simulates a real user, to train the agent with reinforcement learning.\"\"\"\n",
        "\n",
        "    def __init__(self, goal_list, constants, database):\n",
        "        \"\"\"\n",
        "        The constructor for UserSimulator. Sets dialogue config variables.\n",
        "\n",
        "        Parameters:\n",
        "            goal_list (list): User goals loaded from file\n",
        "            constants (dict): Dict of constants loaded from file\n",
        "            database (dict): The database in the format dict(long: dict)\n",
        "        \"\"\"\n",
        "       #print(\"printting goal_list:\", goal_list)\n",
        "        goallist = []\n",
        "        for i in goal_list.keys():\n",
        "          goallist.append(goal_list.get(i))\n",
        "      \n",
        "        #print(\"printting goallist:\", goallist)\n",
        "\n",
        "\n",
        "        self.goallist = goallist\n",
        "        self.max_round = constants['run']['max_round_num']\n",
        "        self.default_key = usersim_default_key\n",
        "        # A list of REQUIRED to be in the first action inform keys\n",
        "        self.init_informs = usersim_required_init_inform_keys\n",
        "        self.no_query = no_query_keys\n",
        "\n",
        "        # TEMP ----\n",
        "        self.database = database\n",
        "        # ---------\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Resets the user sim. by emptying the state and returning the initial action.\n",
        "\n",
        "        Returns:\n",
        "            dict: The initial action of an episode\n",
        "        \"\"\"\n",
        "\n",
        "        self.goal = random.choice(self.goallist)\n",
        "        #print(\"printing goal:\", self.goal)\n",
        "        # Add default slot to requests of goal\n",
        "        self.goal['request_slots'][self.default_key] = 'UNK'\n",
        "        self.state = {}\n",
        "        # Add all inform slots informed by agent or user sim to this dict\n",
        "        self.state['history_slots'] = {}\n",
        "        # Any inform slots for the current user sim action, empty at start of turn\n",
        "        self.state['inform_slots'] = {}\n",
        "        # Current request slots the user sim wants to request\n",
        "        self.state['request_slots'] = {}\n",
        "        # Init. all informs and requests in user goal, remove slots as informs made by user or agent\n",
        "        self.state['rest_slots'] = {}\n",
        "        self.state['rest_slots'].update(self.goal['inform_slots'])\n",
        "        self.state['rest_slots'].update(self.goal['request_slots'])\n",
        "        self.state['intent'] = ''\n",
        "        # False for failure, true for success, init. to failure\n",
        "        self.constraint_check = FAIL\n",
        "\n",
        "        return self._return_init_action()\n",
        "\n",
        "    def _return_init_action(self):\n",
        "        \"\"\"\n",
        "        Returns the initial action of the episode.\n",
        "\n",
        "        The initial action has an intent of request, required init. inform slots and a single request slot.\n",
        "\n",
        "        Returns:\n",
        "            dict: Initial user response\n",
        "        \"\"\"\n",
        "\n",
        "        # Always request\n",
        "        self.state['intent'] = 'request'\n",
        "\n",
        "        if self.goal['inform_slots']:\n",
        "            # Pick all the required init. informs, and add if they exist in goal inform slots\n",
        "            for inform_key in self.init_informs:\n",
        "                if inform_key in self.goal['inform_slots']:\n",
        "                    self.state['inform_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n",
        "                    self.state['rest_slots'].pop(inform_key)\n",
        "                    self.state['history_slots'][inform_key] = self.goal['inform_slots'][inform_key]\n",
        "            # If nothing was added then pick a random one to add\n",
        "            if not self.state['inform_slots']:\n",
        "                key, value = random.choice(list(self.goal['inform_slots'].items()))\n",
        "                self.state['inform_slots'][key] = value\n",
        "                self.state['rest_slots'].pop(key)\n",
        "                self.state['history_slots'][key] = value\n",
        "\n",
        "        # Now add a request, do a random one if something other than def. available\n",
        "        self.goal['request_slots'].pop(self.default_key)\n",
        "        if self.goal['request_slots']:\n",
        "            req_key = random.choice(list(self.goal['request_slots'].keys()))\n",
        "        else:\n",
        "            req_key = self.default_key\n",
        "        self.goal['request_slots'][self.default_key] = 'UNK'\n",
        "        self.state['request_slots'][req_key] = 'UNK'\n",
        "\n",
        "        user_response = {}\n",
        "        user_response['intent'] = self.state['intent']\n",
        "        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n",
        "        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n",
        "\n",
        "        return user_response\n",
        "\n",
        "    def step(self, agent_action):\n",
        "        \"\"\"\n",
        "        Return the response of the user sim. to the agent by using rules that simulate a user.\n",
        "\n",
        "        Given the agent action craft a response by using deterministic rules that simulate (to some extent) a user.\n",
        "        Some parts of the rules are stochastic. Check if the agent has succeeded or lost or still going.\n",
        "\n",
        "        Parameters:\n",
        "            agent_action (dict): The agent action that the user sim. responds to\n",
        "\n",
        "        Returns:\n",
        "            dict: User sim. response\n",
        "            int: Reward\n",
        "            bool: Done flag\n",
        "            int: Success: -1, 0 or 1 for loss, neither win nor loss, win\n",
        "        \"\"\"\n",
        "\n",
        "        # Assertions -----\n",
        "        # No UNK in agent action informs\n",
        "        #print(agent_action['inform_slots'].values())\n",
        "        #print(\"agent action:\",agent_action)\n",
        "        #print(agent_action['intent'])\n",
        "        #print(\"agent_action['inform_slots'].values()\", agent_action['inform_slots'].values())\n",
        "        for value in agent_action['inform_slots'].values():\n",
        "          assert value != 'UNK'\n",
        "          assert value != 'PLACEHOLDER'\n",
        "        # No PLACEHOLDER in agent at all\n",
        "        for value in agent_action['request_slots'].values():\n",
        "          assert value != 'PLACEHOLDER'\n",
        "        # ----------------\n",
        "\n",
        "        self.state['inform_slots'].clear()\n",
        "        self.state['intent'] = ''\n",
        "\n",
        "        done = False\n",
        "        success = NO_OUTCOME\n",
        "        # First check round num, if equal to max then fail\n",
        "        #print(\"agent_action['round']\", agent_action['round'])\n",
        "        #print(\"self.max_round\", self.max_round)\n",
        "        if agent_action['round'] == self.max_round:\n",
        "            done = True\n",
        "            success = FAIL\n",
        "           # print(\"success inside step\", success)\n",
        "            self.state['intent'] = 'done'\n",
        "            self.state['request_slots'].clear()\n",
        "        else:\n",
        "            agent_intent = agent_action['intent']\n",
        "            #print(\"agent_intent:\", agent_intent)\n",
        "            if agent_intent == 'request':\n",
        "                self._response_to_request(agent_action)\n",
        "                #print(\"req:\", success)\n",
        "            elif agent_intent == 'inform':\n",
        "                self._response_to_inform(agent_action)\n",
        "                #print(\"inf:\", success)\n",
        "            elif agent_intent == 'match_found':\n",
        "                self._response_to_match_found(agent_action)\n",
        "                #print(\"match:\", success)\n",
        "            elif agent_intent == 'done':\n",
        "                success = self._response_to_done()\n",
        "                #print(\"success in done step\", success)\n",
        "                self.state['intent'] = 'done'\n",
        "                self.state['request_slots'].clear()\n",
        "                done = True\n",
        "\n",
        "        # Assumptions -------\n",
        "        # If request intent, then make sure request slots\n",
        "        if self.state['intent'] == 'request':\n",
        "            assert self.state['request_slots']\n",
        "        # If inform intent, then make sure inform slots and NO request slots\n",
        "        if self.state['intent'] == 'inform':\n",
        "            assert self.state['inform_slots']\n",
        "            assert not self.state['request_slots']\n",
        "        assert 'UNK' not in self.state['inform_slots'].values()\n",
        "        assert 'PLACEHOLDER' not in self.state['request_slots'].values()\n",
        "        # No overlap between rest and hist\n",
        "        for key in self.state['rest_slots']:\n",
        "            assert key not in self.state['history_slots']\n",
        "        for key in self.state['history_slots']:\n",
        "            assert key not in self.state['rest_slots']\n",
        "        # All slots in both rest and hist should contain the slots for goal\n",
        "        for inf_key in self.goal['inform_slots']:\n",
        "            assert self.state['history_slots'].get(inf_key, False) or self.state['rest_slots'].get(inf_key, False)\n",
        "        for req_key in self.goal['request_slots']:\n",
        "            assert self.state['history_slots'].get(req_key, False) or self.state['rest_slots'].get(req_key,\n",
        "                                                                                                   False), req_key\n",
        "        # Anything in the rest should be in the goal\n",
        "        for key in self.state['rest_slots']:\n",
        "            assert self.goal['inform_slots'].get(key, False) or self.goal['request_slots'].get(key, False)\n",
        "        assert self.state['intent'] != ''\n",
        "        # -----------------------\n",
        "\n",
        "        user_response = {}\n",
        "        user_response['intent'] = self.state['intent']\n",
        "        user_response['request_slots'] = copy.deepcopy(self.state['request_slots'])\n",
        "        user_response['inform_slots'] = copy.deepcopy(self.state['inform_slots'])\n",
        "        reward = reward_function(success, self.max_round)\n",
        "\n",
        "        return user_response, reward, done, True if success is 1 else False\n",
        "\n",
        "    def _response_to_request(self, agent_action):\n",
        "        \"\"\"\n",
        "        Augments the state in response to the agent action having an intent of request.\n",
        "\n",
        "        There are 4 main cases for responding.\n",
        "\n",
        "        Parameters:\n",
        "            agent_action (dict): Intent of request with standard action format (including 'speaker': 'Agent' and\n",
        "                                 'round_num': int)\n",
        "        \"\"\"\n",
        "\n",
        "        agent_request_key = list(agent_action['request_slots'].keys())[0]\n",
        "        # First Case: if agent requests for something that is in the user sims goal inform slots, then inform it\n",
        "        if agent_request_key in self.goal['inform_slots']:\n",
        "            self.state['intent'] = 'inform'\n",
        "            self.state['inform_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n",
        "            self.state['request_slots'].clear()\n",
        "            self.state['rest_slots'].pop(agent_request_key, None)\n",
        "            self.state['history_slots'][agent_request_key] = self.goal['inform_slots'][agent_request_key]\n",
        "        # Second Case: if the agent requests for something in user sims goal request slots and it has already been\n",
        "        # informed, then inform it\n",
        "        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['history_slots']:\n",
        "            self.state['intent'] = 'inform'\n",
        "            self.state['inform_slots'][agent_request_key] = self.state['history_slots'][agent_request_key]\n",
        "            self.state['request_slots'].clear()\n",
        "            assert agent_request_key not in self.state['rest_slots']\n",
        "        # Third Case: if the agent requests for something in the user sims goal request slots and it HASN'T been\n",
        "        # informed, then request it with a random inform\n",
        "        elif agent_request_key in self.goal['request_slots'] and agent_request_key in self.state['rest_slots']:\n",
        "            self.state['request_slots'].clear()\n",
        "            self.state['intent'] = 'request'\n",
        "            self.state['request_slots'][agent_request_key] = 'UNK'\n",
        "            rest_informs = {}\n",
        "            for key, value in list(self.state['rest_slots'].items()):\n",
        "                if value != 'UNK':\n",
        "                    rest_informs[key] = value\n",
        "            if rest_informs:\n",
        "                key_choice, value_choice = random.choice(list(rest_informs.items()))\n",
        "                self.state['inform_slots'][key_choice] = value_choice\n",
        "                self.state['rest_slots'].pop(key_choice)\n",
        "                self.state['history_slots'][key_choice] = value_choice\n",
        "        # Fourth and Final Case: otherwise the user sim does not care about the slot being requested, then inform\n",
        "        # 'anything' as the value of the requested slot\n",
        "        else:\n",
        "            assert agent_request_key not in self.state['rest_slots']\n",
        "            self.state['intent'] = 'inform'\n",
        "            self.state['inform_slots'][agent_request_key] = 'anything'\n",
        "            self.state['request_slots'].clear()\n",
        "            self.state['history_slots'][agent_request_key] = 'anything'\n",
        "\n",
        "    def _response_to_inform(self, agent_action):\n",
        "        \"\"\"\n",
        "        Augments the state in response to the agent action having an intent of inform.\n",
        "\n",
        "        There are 2 main cases for responding. Add the agent inform slots to history slots,\n",
        "        and remove the agent inform slots from the rest and request slots.\n",
        "\n",
        "        Parameters:\n",
        "            agent_action (dict): Intent of inform with standard action format (including 'speaker': 'Agent' and\n",
        "                                 'round_num': int)\n",
        "        \"\"\"\n",
        "\n",
        "        agent_inform_key = list(agent_action['inform_slots'].keys())[0]\n",
        "        agent_inform_value = agent_action['inform_slots'][agent_inform_key]\n",
        "\n",
        "        assert agent_inform_key != self.default_key\n",
        "\n",
        "        # Add all informs (by agent too) to hist slots\n",
        "        self.state['history_slots'][agent_inform_key] = agent_inform_value\n",
        "        # Remove from rest slots if in it\n",
        "        self.state['rest_slots'].pop(agent_inform_key, None)\n",
        "        # Remove from request slots if in it\n",
        "        self.state['request_slots'].pop(agent_inform_key, None)\n",
        "\n",
        "        # First Case: If agent informs something that is in goal informs and the value it informed doesnt match,\n",
        "        # then inform the correct value\n",
        "        if agent_inform_value != self.goal['inform_slots'].get(agent_inform_key, agent_inform_value):\n",
        "            self.state['intent'] = 'inform'\n",
        "            self.state['inform_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n",
        "            self.state['request_slots'].clear()\n",
        "            self.state['history_slots'][agent_inform_key] = self.goal['inform_slots'][agent_inform_key]\n",
        "        # Second Case: Otherwise pick a random action to take\n",
        "        else:\n",
        "            # - If anything in state requests then request it\n",
        "            if self.state['request_slots']:\n",
        "                self.state['intent'] = 'request'\n",
        "            # - Else if something to say in rest slots, pick something\n",
        "            elif self.state['rest_slots']:\n",
        "                def_in = self.state['rest_slots'].pop(self.default_key, False)\n",
        "                if self.state['rest_slots']:\n",
        "                    key, value = random.choice(list(self.state['rest_slots'].items()))\n",
        "                    if value != 'UNK':\n",
        "                        self.state['intent'] = 'inform'\n",
        "                        self.state['inform_slots'][key] = value\n",
        "                        self.state['rest_slots'].pop(key)\n",
        "                        self.state['history_slots'][key] = value\n",
        "                    else:\n",
        "                        self.state['intent'] = 'request'\n",
        "                        self.state['request_slots'][key] = 'UNK'\n",
        "                else:\n",
        "                    self.state['intent'] = 'request'\n",
        "                    self.state['request_slots'][self.default_key] = 'UNK'\n",
        "                if def_in == 'UNK':\n",
        "                    self.state['rest_slots'][self.default_key] = 'UNK'\n",
        "            # - Otherwise respond with 'nothing to say' intent\n",
        "            else:\n",
        "                self.state['intent'] = 'thanks'\n",
        "\n",
        "    def _response_to_match_found(self, agent_action):\n",
        "        \"\"\"\n",
        "        Augments the state in response to the agent action having an intent of match_found.\n",
        "\n",
        "        Check if there is a match in the agent action that works with the current goal.\n",
        "\n",
        "        Parameters:\n",
        "            agent_action (dict): Intent of match_found with standard action format (including 'speaker': 'Agent' and\n",
        "                                 'round_num': int)\n",
        "        \"\"\"\n",
        "\n",
        "        agent_informs = agent_action['inform_slots']\n",
        "\n",
        "        self.state['intent'] = 'thanks'\n",
        "        self.constraint_check = SUCCESS\n",
        "\n",
        "        assert self.default_key in agent_informs\n",
        "        self.state['rest_slots'].pop(self.default_key, None)\n",
        "        self.state['history_slots'][self.default_key] = str(agent_informs[self.default_key])\n",
        "        self.state['request_slots'].pop(self.default_key, None)\n",
        "\n",
        "        if agent_informs[self.default_key] == 'no match available':\n",
        "            self.constraint_check = FAIL\n",
        "\n",
        "        # Check to see if all goal informs are in the agent informs, and that the values match\n",
        "        for key, value in self.goal['inform_slots'].items():\n",
        "            assert value != None\n",
        "            # For items that cannot be in the queries don't check to see if they are in the agent informs here\n",
        "            if key in self.no_query:\n",
        "                continue\n",
        "            # Will return true if key not in agent informs OR if value does not match value of agent informs[key]\n",
        "            if value != agent_informs.get(key, None):\n",
        "                self.constraint_check = FAIL\n",
        "                break\n",
        "\n",
        "        if self.constraint_check == FAIL:\n",
        "            self.state['intent'] = 'reject'\n",
        "            self.state['request_slots'].clear()\n",
        "\n",
        "    def _response_to_done(self):\n",
        "        \"\"\"\n",
        "        Augments the state in response to the agent action having an intent of done.\n",
        "\n",
        "        If the constraint_check is SUCCESS and both the rest and request slots of the state are empty for the agent\n",
        "        to succeed in this episode/conversation.\n",
        "\n",
        "        Returns:\n",
        "            int: Success: -1, 0 or 1 for loss, neither win nor loss, win\n",
        "        \"\"\"\n",
        "\n",
        "        if self.constraint_check == FAIL:\n",
        "            return FAIL\n",
        "\n",
        "        if not self.state['rest_slots']:\n",
        "            assert not self.state['request_slots']\n",
        "        if self.state['rest_slots']:\n",
        "            return FAIL\n",
        "\n",
        "        # TEMP: ----\n",
        "        assert self.state['history_slots'][self.default_key] != 'no match available'\n",
        "\n",
        "        match = copy.deepcopy(self.database[int(self.state['history_slots'][self.default_key])])\n",
        "\n",
        "        for key, value in self.goal['inform_slots'].items():\n",
        "            assert value != None\n",
        "            if key in self.no_query:\n",
        "                continue\n",
        "            if value != match.get(key, None):\n",
        "                assert True is False, 'match: {}\\ngoal: {}'.format(match, self.goal)\n",
        "                break\n",
        "        # ----------\n",
        "        #print(\"SUCCESS\", SUCCESS)\n",
        "        return SUCCESS"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting user_simulator.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziG329HRvNVB",
        "colab_type": "code",
        "outputId": "55d84ef2-5aa5-4175-cb45-c83bebb70ba4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile state_tracker.py\n",
        "from db_query import DBQuery\n",
        "import numpy as np\n",
        "from utils import convert_list_to_dict\n",
        "from dialogue_config import all_intents, all_slots, usersim_default_key\n",
        "import copy\n",
        "\n",
        "\n",
        "class StateTracker:\n",
        "    \"\"\"Tracks the state of the episode/conversation and prepares the state representation for the agent.\"\"\"\n",
        "\n",
        "    def __init__(self, database, constants):\n",
        "        \"\"\"\n",
        "        The constructor of StateTracker.\n",
        "\n",
        "        The constructor of StateTracker which creates a DB query object, creates necessary state rep. dicts, etc. and\n",
        "        calls reset.\n",
        "\n",
        "        Parameters:\n",
        "            database (dict): The database with format dict(long: dict)\n",
        "            constants (dict): Loaded constants in dict\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.db_helper = DBQuery(database)\n",
        "        self.match_key = usersim_default_key\n",
        "        self.intents_dict = convert_list_to_dict(all_intents)\n",
        "        self.num_intents = len(all_intents)\n",
        "        self.slots_dict = convert_list_to_dict(all_slots)\n",
        "        self.num_slots = len(all_slots)\n",
        "        self.max_round_num = constants['run']['max_round_num']\n",
        "        self.none_state = np.zeros(self.get_state_size())\n",
        "        self.reset()\n",
        "\n",
        "    def get_state_size(self):\n",
        "        \"\"\"Returns the state size of the state representation used by the agent.\"\"\"\n",
        "\n",
        "        return 2 * self.num_intents + 7 * self.num_slots + 3 + self.max_round_num\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets current_informs, history and round_num.\"\"\"\n",
        "\n",
        "        self.current_informs = {}\n",
        "        # A list of the dialogues (dicts) by the agent and user so far in the conversation\n",
        "        self.history = []\n",
        "        self.round_num = 0\n",
        "\n",
        "    def print_history(self):\n",
        "        \"\"\"Helper function if you want to see the current history action by action.\"\"\"\n",
        "\n",
        "        for action in self.history:\n",
        "            print(action)\n",
        "\n",
        "    def get_state(self, done=False):\n",
        "        \"\"\"\n",
        "        Returns the state representation as a numpy array which is fed into the agent's neural network.\n",
        "\n",
        "        The state representation contains useful information for the agent about the current state of the conversation.\n",
        "        Processes by the agent to be fed into the neural network. Ripe for experimentation and optimization.\n",
        "\n",
        "        Parameters:\n",
        "            done (bool): Indicates whether this is the last dialogue in the episode/conversation. Default: False\n",
        "\n",
        "        Returns:\n",
        "            numpy.array: A numpy array of shape (state size,)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # If done then fill state with zeros\n",
        "        if done:\n",
        "            return self.none_state\n",
        "\n",
        "        user_action = self.history[-1]\n",
        "        db_results_dict = self.db_helper.get_db_results_for_slots(self.current_informs)\n",
        "        last_agent_action = self.history[-2] if len(self.history) > 1 else None\n",
        "\n",
        "        # Create one-hot of intents to represent the current user action\n",
        "        user_act_rep = np.zeros((self.num_intents,))\n",
        "        user_act_rep[self.intents_dict[user_action['intent']]] = 1.0\n",
        "\n",
        "        # Create bag of inform slots representation to represent the current user action\n",
        "        user_inform_slots_rep = np.zeros((self.num_slots,))\n",
        "        #print(\"user actions:\", user_action['inform_slots'].keys())\n",
        "        for key in user_action['inform_slots'].keys():\n",
        "          user_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
        "          #print(self.slots_dict[key])\n",
        "         # print(user_inform_slots_rep[self.slots_dict[key]])\n",
        "          #user_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
        "          #print(user_inform_slots_rep[self.slots_dict[key]])\n",
        "\n",
        "        # Create bag of request slots representation to represent the current user action\n",
        "        user_request_slots_rep = np.zeros((self.num_slots,))\n",
        "        for key in user_action['request_slots'].keys():\n",
        "            user_request_slots_rep[self.slots_dict[key]] = 1.0\n",
        "\n",
        "        # Create bag of filled_in slots based on the current_slots\n",
        "        current_slots_rep = np.zeros((self.num_slots,))\n",
        "        for key in self.current_informs:\n",
        "            current_slots_rep[self.slots_dict[key]] = 1.0\n",
        "\n",
        "        # Encode last agent intent\n",
        "        agent_act_rep = np.zeros((self.num_intents,))\n",
        "        if last_agent_action:\n",
        "            agent_act_rep[self.intents_dict[last_agent_action['intent']]] = 1.0\n",
        "\n",
        "        # Encode last agent inform slots\n",
        "        agent_inform_slots_rep = np.zeros((self.num_slots,))\n",
        "        if last_agent_action:\n",
        "            for key in last_agent_action['inform_slots'].keys():\n",
        "                agent_inform_slots_rep[self.slots_dict[key]] = 1.0\n",
        "\n",
        "        # Encode last agent request slots\n",
        "        agent_request_slots_rep = np.zeros((self.num_slots,))\n",
        "        if last_agent_action:\n",
        "            for key in last_agent_action['request_slots'].keys():\n",
        "                agent_request_slots_rep[self.slots_dict[key]] = 1.0\n",
        "\n",
        "        # Value representation of the round num\n",
        "        turn_rep = np.zeros((1,)) + self.round_num / 5.\n",
        "\n",
        "        # One-hot representation of the round num\n",
        "        turn_onehot_rep = np.zeros((self.max_round_num,))\n",
        "        turn_onehot_rep[self.round_num - 1] = 1.0\n",
        "\n",
        "        # Representation of DB query results (scaled counts)\n",
        "        kb_count_rep = np.zeros((self.num_slots + 1,)) + db_results_dict['matching_all_constraints'] / 100.\n",
        "        for key in db_results_dict.keys():\n",
        "            if key in self.slots_dict:\n",
        "                kb_count_rep[self.slots_dict[key]] = db_results_dict[key] / 100.\n",
        "\n",
        "        # Representation of DB query results (binary)\n",
        "        kb_binary_rep = np.zeros((self.num_slots + 1,)) + np.sum(db_results_dict['matching_all_constraints'] > 0.)\n",
        "        for key in db_results_dict.keys():\n",
        "            if key in self.slots_dict:\n",
        "                kb_binary_rep[self.slots_dict[key]] = np.sum(db_results_dict[key] > 0.)\n",
        "\n",
        "        state_representation = np.hstack(\n",
        "            [user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep,\n",
        "             agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep,\n",
        "             kb_count_rep]).flatten()\n",
        "\n",
        "        return state_representation\n",
        "\n",
        "    def update_state_agent(self, agent_action):\n",
        "        \"\"\"\n",
        "        Updates the dialogue history with the agent's action and augments the agent's action.\n",
        "\n",
        "        Takes an agent action and updates the history. Also augments the agent_action param with query information and\n",
        "        any other necessary information.\n",
        "\n",
        "        Parameters:\n",
        "            agent_action (dict): The agent action of format dict('intent': string, 'inform_slots': dict,\n",
        "                                 'request_slots': dict) and changed to dict('intent': '', 'inform_slots': {},\n",
        "                                 'request_slots': {}, 'round': int, 'speaker': 'Agent')\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if agent_action['intent'] == 'inform':\n",
        "            assert agent_action['inform_slots']\n",
        "            inform_slots = self.db_helper.fill_inform_slot(agent_action['inform_slots'], self.current_informs)\n",
        "            agent_action['inform_slots'] = inform_slots\n",
        "            assert agent_action['inform_slots']\n",
        "            key, value = list(agent_action['inform_slots'].items())[0]  # Only one\n",
        "            assert key != 'match_found'\n",
        "            assert value != 'PLACEHOLDER', 'KEY: {}'.format(key)\n",
        "            self.current_informs[key] = value\n",
        "        # If intent is match_found then fill the action informs with the matches informs (if there is a match)\n",
        "        elif agent_action['intent'] == 'match_found':\n",
        "            assert not agent_action['inform_slots'], 'Cannot inform and have intent of match found!'\n",
        "            db_results = self.db_helper.get_db_results(self.current_informs)\n",
        "            if db_results:\n",
        "                # Arbitrarily pick the first value of the dict\n",
        "                key, value = list(db_results.items())[0]\n",
        "                agent_action['inform_slots'] = copy.deepcopy(value)\n",
        "                agent_action['inform_slots'][self.match_key] = str(key)\n",
        "            else:\n",
        "                agent_action['inform_slots'][self.match_key] = 'no match available'\n",
        "            self.current_informs[self.match_key] = agent_action['inform_slots'][self.match_key]\n",
        "        agent_action.update({'round': self.round_num, 'speaker': 'Agent'})\n",
        "        self.history.append(agent_action)\n",
        "\n",
        "    def update_state_user(self, user_action):\n",
        "        \"\"\"\n",
        "        Updates the dialogue history with the user's action and augments the user's action.\n",
        "\n",
        "        Takes a user action and updates the history. Also augments the user_action param with necessary information.\n",
        "\n",
        "        Parameters:\n",
        "            user_action (dict): The user action of format dict('intent': string, 'inform_slots': dict,\n",
        "                                 'request_slots': dict) and changed to dict('intent': '', 'inform_slots': {},\n",
        "                                 'request_slots': {}, 'round': int, 'speaker': 'User')\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        for key, value in user_action['inform_slots'].items():\n",
        "            self.current_informs[key] = value\n",
        "        user_action.update({'round': self.round_num, 'speaker': 'User'})\n",
        "        self.history.append(user_action)\n",
        "        self.round_num += 1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting state_tracker.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1KOZpGR5-wH",
        "colab_type": "code",
        "outputId": "66c242df-ca91-4304-c945-9cc45a675aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile error_model_controller.py\n",
        "import random\n",
        "from dialogue_config import usersim_intents\n",
        "\n",
        "\n",
        "class ErrorModelController:\n",
        "    \"\"\"Adds error to the user action.\"\"\"\n",
        "\n",
        "    def __init__(self, db_dict, constants):\n",
        "        \"\"\"\n",
        "        The constructor for ErrorModelController.\n",
        "\n",
        "        Saves items in constants, etc.\n",
        "\n",
        "        Parameters:\n",
        "            db_dict (dict): The database dict with format dict(string: list) where each key is the slot name and\n",
        "                            the list is of possible values\n",
        "            constants (dict): Loaded constants in dict\n",
        "        \"\"\"\n",
        "        self.movie_dict = db_dict\n",
        "        self.slot_error_prob = constants['emc']['slot_error_prob']\n",
        "        self.slot_error_mode = constants['emc']['slot_error_mode']  # [0, 3]\n",
        "        self.intent_error_prob = constants['emc']['intent_error_prob']\n",
        "        self.intents = usersim_intents\n",
        "\n",
        "    def infuse_error(self, frame):\n",
        "        \"\"\"\n",
        "        Takes a semantic frame/action as a dict and adds 'error'.\n",
        "\n",
        "        Given a dict/frame it adds error based on specifications in constants. It can either replace slot values,\n",
        "        replace slot and its values, delete a slot or do all three. It can also randomize the intent.\n",
        "\n",
        "        Parameters:\n",
        "            frame (dict): format dict('intent': '', 'inform_slots': {}, 'request_slots': {}, 'round': int,\n",
        "                          'speaker': 'User')\n",
        "        \"\"\"\n",
        "        #print(\"movie_dict:\", self.movie_dict)\n",
        "        informs_dict = frame['inform_slots']\n",
        "        for key in list(frame['inform_slots'].keys()):\n",
        "          #print(\"key:\", key)\n",
        "          #assert frame['inform_slots'].get(key) in self.movie_dict\n",
        "          assert key in self.movie_dict\n",
        "          if random.random() < self.slot_error_prob:\n",
        "              if self.slot_error_mode == 0:  # replace the slot_value only\n",
        "                  self._slot_value_noise(key, informs_dict)\n",
        "              elif self.slot_error_mode == 1:  # replace slot and its values\n",
        "                  self._slot_noise(key, informs_dict)\n",
        "              elif self.slot_error_mode == 2:  # delete the slot\n",
        "                  self._slot_remove(key, informs_dict)\n",
        "              else:  # Combine all three\n",
        "                  rand_choice = random.random()\n",
        "                  if rand_choice <= 0.33:\n",
        "                      self._slot_value_noise(key, informs_dict)\n",
        "                  elif rand_choice > 0.33 and rand_choice <= 0.66:\n",
        "                      self._slot_noise(key, informs_dict)\n",
        "                  else:\n",
        "                      self._slot_remove(key, informs_dict)\n",
        "        if random.random() < self.intent_error_prob:  # add noise for intent level\n",
        "            frame['intent'] = random.choice(self.intents)\n",
        "\n",
        "    def _slot_value_noise(self, key, informs_dict):\n",
        "        \"\"\"\n",
        "        Selects a new value for the slot given a key and the dict to change.\n",
        "\n",
        "        Parameters:\n",
        "            key (string)\n",
        "            informs_dict (dict)\n",
        "        \"\"\"\n",
        "\n",
        "        informs_dict[key] = random.choice(self.movie_dict[key])\n",
        "\n",
        "    def _slot_noise(self, key, informs_dict):\n",
        "        \"\"\"\n",
        "        Replaces current slot given a key in the informs dict with a new slot and selects a random value for this new slot.\n",
        "\n",
        "        Parameters:\n",
        "            key (string)\n",
        "            informs_dict (dict)\n",
        "        \"\"\"\n",
        "\n",
        "        informs_dict.pop(key)\n",
        "        random_slot = random.choice(list(self.movie_dict.keys()))\n",
        "        informs_dict[random_slot] = random.choice(self.movie_dict[random_slot])\n",
        "\n",
        "    def _slot_remove(self, key, informs_dict):\n",
        "        \"\"\"\n",
        "        Removes the slot given the key from the informs dict.\n",
        "\n",
        "        Parameters:\n",
        "            key (string)\n",
        "            informs_dict (dict)\n",
        "        \"\"\"\n",
        "\n",
        "        informs_dict.pop(key)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting error_model_controller.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBv4A987gr26",
        "colab_type": "code",
        "outputId": "a846b1bc-0817-42fa-9338-c286d91192bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%%writefile dqn_agent.py\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "import random, copy\n",
        "import numpy as np\n",
        "from dialogue_config import rule_requests, agent_actions\n",
        "import re\n",
        "\n",
        "\n",
        "# Some of the code based off of https://jaromiru.com/2016/09/27/lets-make-a-dqn-theory/\n",
        "# Note: In original paper's code the epsilon is not annealed and annealing is not implemented in this code either\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "    \"\"\"The DQN agent that interacts with the user.\"\"\"\n",
        "\n",
        "    def __init__(self, state_size, constants):\n",
        "        \"\"\"\n",
        "        The constructor of DQNAgent.\n",
        "\n",
        "        The constructor of DQNAgent which saves constants, sets up neural network graphs, etc.\n",
        "\n",
        "        Parameters:\n",
        "            state_size (int): The state representation size or length of numpy array\n",
        "            constants (dict): Loaded constants in dict\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.C = constants['agent']\n",
        "        self.memory = []\n",
        "        self.memory_index = 0\n",
        "        self.max_memory_size = self.C['max_mem_size']\n",
        "        self.eps = self.C['epsilon_init']\n",
        "        self.vanilla = self.C['vanilla']\n",
        "        self.lr = self.C['learning_rate']\n",
        "        self.gamma = self.C['gamma']\n",
        "        self.batch_size = self.C['batch_size']\n",
        "        self.hidden_size = self.C['dqn_hidden_size']\n",
        "\n",
        "        self.load_weights_file_path = self.C['load_weights_file_path']\n",
        "        self.save_weights_file_path = self.C['save_weights_file_path']\n",
        "\n",
        "        if self.max_memory_size < self.batch_size:\n",
        "            raise ValueError('Max memory size must be at least as great as batch size!')\n",
        "\n",
        "        self.state_size = state_size\n",
        "        self.possible_actions = agent_actions\n",
        "        self.num_actions = len(self.possible_actions)\n",
        "\n",
        "        self.rule_request_set = rule_requests\n",
        "\n",
        "        self.beh_model = self._build_model()\n",
        "        self.tar_model = self._build_model()\n",
        "\n",
        "        self._load_weights()\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def _build_model(self):\n",
        "        \"\"\"Builds and returns model/graph of neural network.\"\"\"\n",
        "\n",
        "        model = Sequential()\n",
        "        model.add(Dense(self.hidden_size, input_dim=self.state_size, activation='relu'))\n",
        "        model.add(Dense(self.num_actions, activation='linear'))\n",
        "        model.compile(loss='mse', optimizer=Adam(lr=self.lr))\n",
        "        return model\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Resets the rule-based variables.\"\"\"\n",
        "\n",
        "        self.rule_current_slot_index = 0\n",
        "        self.rule_phase = 'not done'\n",
        "\n",
        "    def get_action(self, state, use_rule=False):\n",
        "        \"\"\"\n",
        "        Returns the action of the agent given a state.\n",
        "\n",
        "        Gets the action of the agent given the current state. Either the rule-based policy or the neural networks are\n",
        "        used to respond.\n",
        "\n",
        "        Parameters:\n",
        "            state (numpy.array): The database with format dict(long: dict)\n",
        "            use_rule (bool): Indicates whether or not to use the rule-based policy, which depends on if this was called\n",
        "                             in warmup or training. Default: False\n",
        "\n",
        "        Returns:\n",
        "            int: The index of the action in the possible actions\n",
        "            dict: The action/response itself\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if self.eps > random.random():\n",
        "            index = random.randint(0, self.num_actions - 1)\n",
        "            action = self._map_index_to_action(index)\n",
        "            return index, action\n",
        "        else:\n",
        "            if use_rule:\n",
        "                return self._rule_action()\n",
        "            else:\n",
        "                return self._dqn_action(state)\n",
        "\n",
        "    def _rule_action(self):\n",
        "        \"\"\"\n",
        "        Returns a rule-based policy action.\n",
        "\n",
        "        Selects the next action of a simple rule-based policy.\n",
        "\n",
        "        Returns:\n",
        "            int: The index of the action in the possible actions\n",
        "            dict: The action/response itself\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if self.rule_current_slot_index < len(self.rule_request_set):\n",
        "            slot = self.rule_request_set[self.rule_current_slot_index]\n",
        "            self.rule_current_slot_index += 1\n",
        "            rule_response = {'intent': 'request', 'inform_slots': {}, 'request_slots': {slot: 'UNK'}}\n",
        "        elif self.rule_phase == 'not done':\n",
        "            rule_response = {'intent': 'match_found', 'inform_slots': {}, 'request_slots': {}}\n",
        "            self.rule_phase = 'done'\n",
        "        elif self.rule_phase == 'done':\n",
        "            rule_response = {'intent': 'done', 'inform_slots': {}, 'request_slots': {}}\n",
        "        else:\n",
        "            raise Exception('Should not have reached this clause')\n",
        "\n",
        "        index = self._map_action_to_index(rule_response)\n",
        "        return index, rule_response\n",
        "\n",
        "    def _map_action_to_index(self, response):\n",
        "        \"\"\"\n",
        "        Maps an action to an index from possible actions.\n",
        "\n",
        "        Parameters:\n",
        "            response (dict)\n",
        "\n",
        "        Returns:\n",
        "            int\n",
        "        \"\"\"\n",
        "\n",
        "        for (i, action) in enumerate(self.possible_actions):\n",
        "            if response == action:\n",
        "                return i\n",
        "        raise ValueError('Response: {} not found in possible actions'.format(response))\n",
        "\n",
        "    def _dqn_action(self, state):\n",
        "        \"\"\"\n",
        "        Returns a behavior model output given a state.\n",
        "\n",
        "        Parameters:\n",
        "            state (numpy.array)\n",
        "\n",
        "        Returns:\n",
        "            int: The index of the action in the possible actions\n",
        "            dict: The action/response itself\n",
        "        \"\"\"\n",
        "\n",
        "        index = np.argmax(self._dqn_predict_one(state))\n",
        "        action = self._map_index_to_action(index)\n",
        "        return index, action\n",
        "\n",
        "    def _map_index_to_action(self, index):\n",
        "        \"\"\"\n",
        "        Maps an index to an action in possible actions.\n",
        "\n",
        "        Parameters:\n",
        "            index (int)\n",
        "\n",
        "        Returns:\n",
        "            dict\n",
        "        \"\"\"\n",
        "\n",
        "        for (i, action) in enumerate(self.possible_actions):\n",
        "            if index == i:\n",
        "                return copy.deepcopy(action)\n",
        "        raise ValueError('Index: {} not in range of possible actions'.format(index))\n",
        "\n",
        "    def _dqn_predict_one(self, state, target=False):\n",
        "        \"\"\"\n",
        "        Returns a model prediction given a state.\n",
        "\n",
        "        Parameters:\n",
        "            state (numpy.array)\n",
        "            target (bool)\n",
        "\n",
        "        Returns:\n",
        "            numpy.array\n",
        "        \"\"\"\n",
        "\n",
        "        return self._dqn_predict(state.reshape(1, self.state_size), target=target).flatten()\n",
        "\n",
        "    def _dqn_predict(self, states, target=False):\n",
        "        \"\"\"\n",
        "        Returns a model prediction given an array of states.\n",
        "\n",
        "        Parameters:\n",
        "            states (numpy.array)\n",
        "            target (bool)\n",
        "\n",
        "        Returns:\n",
        "            numpy.array\n",
        "        \"\"\"\n",
        "\n",
        "        if target:\n",
        "            return self.tar_model.predict(states)\n",
        "        else:\n",
        "            return self.beh_model.predict(states)\n",
        "\n",
        "    def add_experience(self, state, action, reward, next_state, done):\n",
        "        \"\"\"\n",
        "        Adds an experience tuple made of the parameters to the memory.\n",
        "\n",
        "        Parameters:\n",
        "            state (numpy.array)\n",
        "            action (int)\n",
        "            reward (int)\n",
        "            next_state (numpy.array)\n",
        "            done (bool)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        if len(self.memory) < self.max_memory_size:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.memory_index] = (state, action, reward, next_state, done)\n",
        "        self.memory_index = (self.memory_index + 1) % self.max_memory_size\n",
        "\n",
        "    def empty_memory(self):\n",
        "        \"\"\"Empties the memory and resets the memory index.\"\"\"\n",
        "\n",
        "        self.memory = []\n",
        "        self.memory_index = 0\n",
        "\n",
        "    def is_memory_full(self):\n",
        "        \"\"\"Returns true if the memory is full.\"\"\"\n",
        "\n",
        "        return len(self.memory) == self.max_memory_size\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains the agent by improving the behavior model given the memory tuples.\n",
        "\n",
        "        Takes batches of memories from the memory pool and processing them. The processing takes the tuples and stacks\n",
        "        them in the correct format for the neural network and calculates the Bellman equation for Q-Learning.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Calc. num of batches to run\n",
        "        num_batches = len(self.memory) // self.batch_size\n",
        "        for b in range(num_batches):\n",
        "            batch = random.sample(self.memory, self.batch_size)\n",
        "\n",
        "            states = np.array([sample[0] for sample in batch])\n",
        "            next_states = np.array([sample[3] for sample in batch])\n",
        "\n",
        "            assert states.shape == (self.batch_size, self.state_size), 'States Shape: {}'.format(states.shape)\n",
        "            assert next_states.shape == states.shape\n",
        "\n",
        "            beh_state_preds = self._dqn_predict(states)  # For leveling error\n",
        "            if not self.vanilla:\n",
        "                beh_next_states_preds = self._dqn_predict(next_states)  # For indexing for DDQN\n",
        "            tar_next_state_preds = self._dqn_predict(next_states, target=True)  # For target value for DQN (& DDQN)\n",
        "\n",
        "            inputs = np.zeros((self.batch_size, self.state_size))\n",
        "            targets = np.zeros((self.batch_size, self.num_actions))\n",
        "\n",
        "            for i, (s, a, r, s_, d) in enumerate(batch):\n",
        "                t = beh_state_preds[i]\n",
        "                if not self.vanilla:\n",
        "                    t[a] = r + self.gamma * tar_next_state_preds[i][np.argmax(beh_next_states_preds[i])] * (not d)\n",
        "                else:\n",
        "                    t[a] = r + self.gamma * np.amax(tar_next_state_preds[i]) * (not d)\n",
        "\n",
        "                inputs[i] = s\n",
        "                targets[i] = t\n",
        "\n",
        "            self.beh_model.fit(inputs, targets, epochs=1, verbose=0)\n",
        "\n",
        "    def copy(self):\n",
        "        \"\"\"Copies the behavior model's weights into the target model's weights.\"\"\"\n",
        "\n",
        "        self.tar_model.set_weights(self.beh_model.get_weights())\n",
        "\n",
        "    def save_weights(self):\n",
        "        \"\"\"Saves the weights of both models in two h5 files.\"\"\"\n",
        "\n",
        "        if not self.save_weights_file_path:\n",
        "            return\n",
        "        beh_save_file_path = re.sub(r'\\.h5', r'_beh.h5', self.save_weights_file_path)\n",
        "        self.beh_model.save_weights(beh_save_file_path)\n",
        "        tar_save_file_path = re.sub(r'\\.h5', r'_tar.h5', self.save_weights_file_path)\n",
        "        self.tar_model.save_weights(tar_save_file_path)\n",
        "\n",
        "    def _load_weights(self):\n",
        "        \"\"\"Loads the weights of both models from two h5 files.\"\"\"\n",
        "\n",
        "        if not self.load_weights_file_path:\n",
        "            return\n",
        "        beh_load_file_path = re.sub(r'\\.h5', r'_beh.h5', self.load_weights_file_path)\n",
        "        self.beh_model.load_weights(beh_load_file_path,by_name=True)\n",
        "        tar_load_file_path = re.sub(r'\\.h5', r'_tar.h5', self.load_weights_file_path)\n",
        "        self.tar_model.load_weights(tar_load_file_path,by_name=True)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting dqn_agent.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJKc6ZHMNlDj",
        "colab_type": "text"
      },
      "source": [
        "# Training the agent\n",
        "here you can enter the values into console to test the agent sample syntax to input values.\n",
        "*   intent values: request , inform, thanks , done, reject\n",
        "*  you can choose some of slot values from the datset above \n",
        "1.  inform/ from_stop:hamilton/\n",
        "2.  request//arrival_time\n",
        "3.  done//\n",
        "4.  thanks//\n",
        "\n",
        " This brings the closest ticket to the given user constrains\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VheozImabm3Y",
        "colab_type": "code",
        "outputId": "e1075f12-b1aa-4e04-9cd9-26cf06c94eea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --constants_path \"constants.json\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Warmup Started...\n",
            "Response: inform/from_stop:hamilton/\n",
            "Response: inform/to_stop:seattle/\n",
            "Response: inform/departure_time:10:30am/\n",
            "Response: request//arrival_time/\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'from_stop': 'UNK'}, 'round': 1, 'speaker': 'Agent'}\n",
            "Response: inform/to_stop:seattle/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'to_stop': 'UNK'}, 'round': 2, 'speaker': 'Agent'}\n",
            "Response: inform/departure_time:10:30am/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'departure_time': 'UNK'}, 'round': 3, 'speaker': 'Agent'}\n",
            "Response: request//arrival_time/\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'direction': 'UNK'}, 'round': 4, 'speaker': 'Agent'}\n",
            "Response: inform/direction:seattle/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'vehicle': 'UNK'}, 'round': 5, 'speaker': 'Agent'}\n",
            "Response: inform/vehicle:subway/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'match_found', 'inform_slots': {'from_stop': 'hamilton', 'to_stop': 'Seattle', 'vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '10:30am', 'arrival_time': '12:30pm', 'ticket': '0'}, 'request_slots': {}, 'round': 6, 'speaker': 'Agent'}\n",
            "Response: done//\n",
            "Success?: 1\n",
            "Response: inform/from_stop:seattle/\n",
            "Response: inform/to_stop:albany/\n",
            "Response: inform/departure_time:9:50 pm/\n",
            "Response: request//arrival_time/\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'from_stop': 'UNK'}, 'round': 1, 'speaker': 'Agent'}\n",
            "Response: inform/to_stop:albany/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'to_stop': 'UNK'}, 'round': 2, 'speaker': 'Agent'}\n",
            "Response: inform/departure_time:9:50 pm/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'departure_time': 'UNK'}, 'round': 3, 'speaker': 'Agent'}\n",
            "Response: request//arrival_time\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'direction': 'UNK'}, 'round': 4, 'speaker': 'Agent'}\n",
            "Response: inform/direction:albany/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'vehicle': 'UNK'}, 'round': 5, 'speaker': 'Agent'}\n",
            "Response: inform/vehicle:subway/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'match_found', 'inform_slots': {'from_stop': 'hamilton', 'to_stop': 'Seattle', 'vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '10:30am', 'arrival_time': '12:30pm', 'ticket': '0'}, 'request_slots': {}, 'round': 6, 'speaker': 'Agent'}\n",
            "Response: done//\n",
            "Success?: -1\n",
            "Response: request//arrival_time\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'from_stop': 'UNK'}, 'round': 1, 'speaker': 'Agent'}\n",
            "Response: inform/to_stop:albany/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'to_stop': 'UNK'}, 'round': 2, 'speaker': 'Agent'}\n",
            "Response: inform/direction:nyc/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'departure_time': 'UNK'}, 'round': 3, 'speaker': 'Agent'}\n",
            "Response: inform/departure_time:9:50 pm/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'direction': 'UNK'}, 'round': 4, 'speaker': 'Agent'}\n",
            "Response: inform/direction:nyc/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'request', 'inform_slots': {}, 'request_slots': {'vehicle': 'UNK'}, 'round': 5, 'speaker': 'Agent'}\n",
            "Response: inform/vehicle:subway/\n",
            "Response: done//\n",
            "Success?: 0\n",
            "Agent Action: {'intent': 'match_found', 'inform_slots': {'from_stop': 'hamilton', 'to_stop': 'Seattle', 'vehicle': 'subway', 'direction': 'nyc', 'duration': '2 hours', 'departure_time': '10:30am', 'arrival_time': '12:30pm', 'ticket': '0'}, 'request_slots': {}, 'round': 6, 'speaker': 'Agent'}\n",
            "Response: done//\n",
            "Success?: -1\n",
            "Response: Traceback (most recent call last):\n",
            "  File \"train.py\", line 190, in <module>\n",
            "    warmup_run()\n",
            "  File \"train.py\", line 99, in warmup_run\n",
            "    episode_reset()\n",
            "  File \"train.py\", line 178, in episode_reset\n",
            "    user_action = user.reset()\n",
            "  File \"/content/goal-oriented/user.py\", line 25, in reset\n",
            "    return self._return_response()\n",
            "  File \"/content/goal-oriented/user.py\", line 43, in _return_response\n",
            "    input_string = input('Response: ')\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwtjUZkgKTC3",
        "colab_type": "code",
        "outputId": "187ff336-0fe7-4047-dcc8-cad2d42c77b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "source": [
        "!python test.py --constants_path \"constants.json\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Testing Started...\n",
            "Response: inform/from_stop:nyc/\n",
            "Response: inform/to_stop:Seattle/\n",
            "Response: request//departure_time\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2019-11-25 21:05:36.956685: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-11-25 21:05:36.959670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2927b80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2019-11-25 21:05:36.959724: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2019-11-25 21:05:37.057987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2019-11-25 21:05:37.154722: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-11-25 21:05:37.154845: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (40337eceb747): /proc/driver/nvidia/version does not exist\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Agent Action: {'intent': 'inform', 'inform_slots': {'departure_time': '10:30am'}, 'request_slots': {}, 'round': 1, 'speaker': 'Agent'}\n",
            "Response: Traceback (most recent call last):\n",
            "  File \"test.py\", line 116, in <module>\n",
            "    test_run()\n",
            "  File \"test.py\", line 88, in test_run\n",
            "    user_action, reward, done, success = user.step(agent_action)\n",
            "  File \"/content/goal-oriented/user.py\", line 122, in step\n",
            "    user_response = self._return_response()\n",
            "  File \"/content/goal-oriented/user.py\", line 43, in _return_response\n",
            "    input_string = input('Response: ')\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AisT7t5TqWCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}